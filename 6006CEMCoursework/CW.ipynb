{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIABETES PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This script preprocessing includes how to check for missing values,as well as replace missing values, categorize, and process non-numeric values (OUTCOME (objec))and duplicate values, and outliers and replace unreasonable values (0).**   \n",
    "\n",
    "**The training data were compared with and without scaling.**  \n",
    "\n",
    "**The model uses logistic regression, k-NN, random forest and MLP. PCA and the model were compared with and without scaling, and the confusion matrix was evaluated in each link.**  \n",
    "\n",
    "**The hyperparametric tuning is optimized by grid search and random search, and the optimal model is selected by cross-validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import  Essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,recall_score,roc_auc_score, precision_score,f1_score,plot_roc_curve,plot_roc_curve, plot_confusion_matrix,classification_report\n",
    "from HF_Functions import correlated_map,label_encoder,grab_col_names,cat_summary,detect_outliers\n",
    "import warnings\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analyse and preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>62</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.127</td>\n",
       "      <td>47</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "      <td>31</td>\n",
       "      <td>125</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.233</td>\n",
       "      <td>23</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>68</td>\n",
       "      <td>42</td>\n",
       "      <td>250</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.365</td>\n",
       "      <td>24</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139</td>\n",
       "      <td>62</td>\n",
       "      <td>41</td>\n",
       "      <td>480</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.536</td>\n",
       "      <td>21</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            2      138             62             35        0  33.6   \n",
       "1            0       84             82             31      125  38.2   \n",
       "2            0      145              0              0        0  44.2   \n",
       "3            0      135             68             42      250  42.3   \n",
       "4            1      139             62             41      480  40.7   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age Outcome  \n",
       "0                     0.127   47     YES  \n",
       "1                     0.233   23      NO  \n",
       "2                     0.630   31     YES  \n",
       "3                     0.365   24     YES  \n",
       "4                     0.536   21      NO  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Dataset Showing the dataset information\n",
    "df = pd.read_csv(\"datasets/diabetes-dataset.csv\")\n",
    "df.head()# check first 5 rows of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape# check No. of columns and rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               2000 non-null   int64  \n",
      " 1   Glucose                   2000 non-null   int64  \n",
      " 2   BloodPressure             2000 non-null   int64  \n",
      " 3   SkinThickness             2000 non-null   int64  \n",
      " 4   Insulin                   2000 non-null   int64  \n",
      " 5   BMI                       2000 non-null   float64\n",
      " 6   DiabetesPedigreeFunction  2000 non-null   float64\n",
      " 7   Age                       2000 non-null   int64  \n",
      " 8   Outcome                   2000 non-null   object \n",
      "dtypes: float64(2), int64(6), object(1)\n",
      "memory usage: 140.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()#Check feature information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>10%</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>90%</th>\n",
       "      <th>95%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pregnancies</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.70350</td>\n",
       "      <td>3.306063</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>13.00000</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>121.18250</td>\n",
       "      <td>32.068636</td>\n",
       "      <td>0.000</td>\n",
       "      <td>85.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>117.000</td>\n",
       "      <td>141.000</td>\n",
       "      <td>168.0000</td>\n",
       "      <td>181.000</td>\n",
       "      <td>195.00000</td>\n",
       "      <td>199.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressure</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>69.14550</td>\n",
       "      <td>19.188315</td>\n",
       "      <td>0.000</td>\n",
       "      <td>54.000</td>\n",
       "      <td>63.500</td>\n",
       "      <td>72.000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>88.0000</td>\n",
       "      <td>90.000</td>\n",
       "      <td>106.00000</td>\n",
       "      <td>122.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThickness</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>20.93500</td>\n",
       "      <td>16.103243</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>44.050</td>\n",
       "      <td>52.00000</td>\n",
       "      <td>110.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insulin</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>80.25400</td>\n",
       "      <td>111.180534</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>130.000</td>\n",
       "      <td>210.0000</td>\n",
       "      <td>293.000</td>\n",
       "      <td>495.00000</td>\n",
       "      <td>744.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>32.19300</td>\n",
       "      <td>8.149901</td>\n",
       "      <td>0.000</td>\n",
       "      <td>23.700</td>\n",
       "      <td>27.375</td>\n",
       "      <td>32.300</td>\n",
       "      <td>36.800</td>\n",
       "      <td>42.1000</td>\n",
       "      <td>45.010</td>\n",
       "      <td>52.90000</td>\n",
       "      <td>80.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.47093</td>\n",
       "      <td>0.323553</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.164</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.8782</td>\n",
       "      <td>1.136</td>\n",
       "      <td>1.60098</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>33.09050</td>\n",
       "      <td>11.786423</td>\n",
       "      <td>21.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>58.000</td>\n",
       "      <td>67.00000</td>\n",
       "      <td>81.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count       mean         std     min     10%  \\\n",
       "Pregnancies               2000.0    3.70350    3.306063   0.000   0.000   \n",
       "Glucose                   2000.0  121.18250   32.068636   0.000  85.000   \n",
       "BloodPressure             2000.0   69.14550   19.188315   0.000  54.000   \n",
       "SkinThickness             2000.0   20.93500   16.103243   0.000   0.000   \n",
       "Insulin                   2000.0   80.25400  111.180534   0.000   0.000   \n",
       "BMI                       2000.0   32.19300    8.149901   0.000  23.700   \n",
       "DiabetesPedigreeFunction  2000.0    0.47093    0.323553   0.078   0.164   \n",
       "Age                       2000.0   33.09050   11.786423  21.000  22.000   \n",
       "\n",
       "                             25%      50%      75%       90%      95%  \\\n",
       "Pregnancies                1.000    3.000    6.000    9.0000   10.000   \n",
       "Glucose                   99.000  117.000  141.000  168.0000  181.000   \n",
       "BloodPressure             63.500   72.000   80.000   88.0000   90.000   \n",
       "SkinThickness              0.000   23.000   32.000   40.0000   44.050   \n",
       "Insulin                    0.000   40.000  130.000  210.0000  293.000   \n",
       "BMI                       27.375   32.300   36.800   42.1000   45.010   \n",
       "DiabetesPedigreeFunction   0.244    0.376    0.624    0.8782    1.136   \n",
       "Age                       24.000   29.000   40.000   50.0000   58.000   \n",
       "\n",
       "                                99%     max  \n",
       "Pregnancies                13.00000   17.00  \n",
       "Glucose                   195.00000  199.00  \n",
       "BloodPressure             106.00000  122.00  \n",
       "SkinThickness              52.00000  110.00  \n",
       "Insulin                   495.00000  744.00  \n",
       "BMI                        52.90000   80.60  \n",
       "DiabetesPedigreeFunction    1.60098    2.42  \n",
       "Age                        67.00000   81.00  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive statistics of the data set accessed.\n",
    "df.describe([0.10,0.25,0.50,0.75,0.90,0.95,0.99]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Checking Missing values and Handling Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has no missing values\n"
     ]
    }
   ],
   "source": [
    "### Check Missing values\n",
    "\n",
    "# Does data has some missing values?\n",
    "dataset = df.isnull().sum().sum()\n",
    "if dataset == 0:\n",
    "    print('Data has no missing values')\n",
    "else:\n",
    "    print('Data has missing values')#checks variables have any Nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               2000 non-null   int64  \n",
      " 1   Glucose                   2000 non-null   int64  \n",
      " 2   BloodPressure             2000 non-null   int64  \n",
      " 3   SkinThickness             2000 non-null   int64  \n",
      " 4   Insulin                   2000 non-null   int64  \n",
      " 5   BMI                       2000 non-null   float64\n",
      " 6   DiabetesPedigreeFunction  2000 non-null   float64\n",
      " 7   Age                       2000 non-null   int64  \n",
      " 8   Outcome                   2000 non-null   object \n",
      "dtypes: float64(2), int64(6), object(1)\n",
      "memory usage: 140.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"When we examine NaN values with isnull() in the data set,\\n no records are found; however, too many 0's stand out in the columns such as blood pressure, BMI, skin thickness.\\n  This is illogical, so these values should be treated as missing values.\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()# recheck \n",
    "'''When we examine NaN values with isnull() in the data set,\n",
    " no records are found; however, too many 0's stand out in the columns such as blood pressure, BMI, skin thickness.\n",
    "  This is illogical, so these values should be treated as missing values.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the value of 0 with NAN\n",
    "df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']] = df[['Glucose','BloodPressure','SkinThickness','Insulin','BMI']].replace(0,np.NaN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                   0\n",
       "Glucose                      13\n",
       "BloodPressure                90\n",
       "SkinThickness               573\n",
       "Insulin                     956\n",
       "BMI                          28\n",
       "DiabetesPedigreeFunction      0\n",
       "Age                           0\n",
       "Outcome                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we can  check where are missing and (0)NAN values   \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.127</td>\n",
       "      <td>47</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.233</td>\n",
       "      <td>23</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.365</td>\n",
       "      <td>24</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.536</td>\n",
       "      <td>21</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            2    138.0           62.0           35.0      NaN  33.6   \n",
       "1            0     84.0           82.0           31.0    125.0  38.2   \n",
       "2            0    145.0            NaN            NaN      NaN  44.2   \n",
       "3            0    135.0           68.0           42.0    250.0  42.3   \n",
       "4            1    139.0           62.0           41.0    480.0  40.7   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age Outcome  \n",
       "0                     0.127   47     YES  \n",
       "1                     0.233   23      NO  \n",
       "2                     0.630   31     YES  \n",
       "3                     0.365   24     YES  \n",
       "4                     0.536   21      NO  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols, num_cols, cat_but_car = grab_col_names(df)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to upper case for ease of input\n",
    "df.columns = [col.upper() for col in df.columns]\n",
    "cat_cols = [x.upper() for x in cat_cols]\n",
    "num_cols = [x.upper() for x in num_cols]\n",
    "cat_but_car = [x.upper() for x in cat_but_car]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "columns = columns.drop(\"OUTCOME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"1 .Violent method: we can delete rows with missing values: missing values can be dealt with by deleting rows or columns with null values. \n",
    "The disadvantage is that a large amount of information is lost and the percentage of missing values is too large to be effective.\"\"\" \n",
    "\"\"\"2. We estimated the missing values using the mean/median.\n",
    "Prevents data loss leading to deleted rows or columns and works well on a small data set and is easy to implement. \"\"\"\n",
    "'''To fill in the missing values, \n",
    "we will group the columns with empty values according to OUTCOME \n",
    "and add the median value of the target variable corresponding to the relevant blank value.'''\n",
    "for i in columns:   \n",
    "    #The action of taking the median value for values with a partial characteristic of 0.\n",
    "  df[i] = df[i].fillna(df.groupby(\"OUTCOME\")[i].transform(\"median\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PREGNANCIES</th>\n",
       "      <th>GLUCOSE</th>\n",
       "      <th>BLOODPRESSURE</th>\n",
       "      <th>SKINTHICKNESS</th>\n",
       "      <th>INSULIN</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DIABETESPEDIGREEFUNCTION</th>\n",
       "      <th>AGE</th>\n",
       "      <th>OUTCOME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>138.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.127</td>\n",
       "      <td>47</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>38.2</td>\n",
       "      <td>0.233</td>\n",
       "      <td>23</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.365</td>\n",
       "      <td>24</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>139.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>40.7</td>\n",
       "      <td>0.536</td>\n",
       "      <td>21</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PREGNANCIES  GLUCOSE  BLOODPRESSURE  SKINTHICKNESS  INSULIN   BMI  \\\n",
       "0            2    138.0           62.0           35.0    167.0  33.6   \n",
       "1            0     84.0           82.0           31.0    125.0  38.2   \n",
       "2            0    145.0           75.0           32.0    167.0  44.2   \n",
       "3            0    135.0           68.0           42.0    250.0  42.3   \n",
       "4            1    139.0           62.0           41.0    480.0  40.7   \n",
       "\n",
       "   DIABETESPEDIGREEFUNCTION  AGE OUTCOME  \n",
       "0                     0.127   47     YES  \n",
       "1                     0.233   23      NO  \n",
       "2                     0.630   31     YES  \n",
       "3                     0.365   24     YES  \n",
       "4                     0.536   21      NO  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()# some  0 values  has replace to median values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PREGNANCIES                  17\n",
       "GLUCOSE                     135\n",
       "BLOODPRESSURE                46\n",
       "SKINTHICKNESS                52\n",
       "INSULIN                     181\n",
       "BMI                         246\n",
       "DIABETESPEDIGREEFUNCTION    505\n",
       "AGE                          52\n",
       "OUTCOME                       2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()# Checking unique values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Check duplicated values and Handling duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1256"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dplicated=df.duplicated().sum()   # check  dups value in file\n",
    "Dplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    !!! IMPORTANT!!!\\n Because the sample is less than 1000 after removing the duplicates values and to get a better model,\\n only the code is shown here without removing the duplicate values'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''    !!! IMPORTANT!!!\n",
    " Because the sample is less than 1000 after removing the duplicates values and to get a better model,\n",
    " only the code is shown here without removing the duplicate values'''\n",
    "#df.drop_duplicates()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Detection and Handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Counter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9576/2201595452.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moutliers_to_drop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_outliers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"PREGNANCIES\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'GLUCOSE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BLOODPRESSURE'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SKINTHICKNESS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'INSULIN'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BMI'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'DIABETESPEDIGREEFUNCTION'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AGE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32me:\\文件练习\\6006CW\\HF_Functions.py\u001b[0m in \u001b[0;36mdetect_outliers\u001b[1;34m(df, n, features)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m     \u001b[1;31m# select observations containing more than 2 outliers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m     \u001b[0moutlier_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutlier_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m     \u001b[0mmultiple_outliers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutlier_indices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Counter' is not defined"
     ]
    }
   ],
   "source": [
    "outliers_to_drop = detect_outliers(df, 2 ,[\"PREGNANCIES\", 'GLUCOSE', 'BLOODPRESSURE', 'SKINTHICKNESS', 'INSULIN', 'BMI', 'DIABETESPEDIGREEFUNCTION', 'AGE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[outliers_to_drop] # Show the outliers rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outliers_to_drop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9576/4085045613.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moutliers_to_drop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# drop  outlier values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'outliers_to_drop' is not defined"
     ]
    }
   ],
   "source": [
    "df.drop(df.loc[outliers_to_drop].index, inplace=True)# drop  outlier values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PREGNANCIES</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.70350</td>\n",
       "      <td>3.306063</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>6.000</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLUCOSE</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>121.98000</td>\n",
       "      <td>30.563748</td>\n",
       "      <td>44.000</td>\n",
       "      <td>99.000</td>\n",
       "      <td>117.000</td>\n",
       "      <td>141.000</td>\n",
       "      <td>199.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLOODPRESSURE</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>72.39300</td>\n",
       "      <td>11.961191</td>\n",
       "      <td>24.000</td>\n",
       "      <td>64.000</td>\n",
       "      <td>72.000</td>\n",
       "      <td>80.000</td>\n",
       "      <td>122.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SKINTHICKNESS</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>29.21300</td>\n",
       "      <td>9.217815</td>\n",
       "      <td>7.000</td>\n",
       "      <td>25.000</td>\n",
       "      <td>28.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>110.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSULIN</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>141.20100</td>\n",
       "      <td>84.007709</td>\n",
       "      <td>14.000</td>\n",
       "      <td>105.000</td>\n",
       "      <td>105.000</td>\n",
       "      <td>167.000</td>\n",
       "      <td>744.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>32.62445</td>\n",
       "      <td>7.194776</td>\n",
       "      <td>18.200</td>\n",
       "      <td>27.600</td>\n",
       "      <td>32.300</td>\n",
       "      <td>36.800</td>\n",
       "      <td>80.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIABETESPEDIGREEFUNCTION</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>0.47093</td>\n",
       "      <td>0.323553</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.624</td>\n",
       "      <td>2.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>2000.0</td>\n",
       "      <td>33.09050</td>\n",
       "      <td>11.786423</td>\n",
       "      <td>21.000</td>\n",
       "      <td>24.000</td>\n",
       "      <td>29.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>81.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           count       mean        std     min      25%  \\\n",
       "PREGNANCIES               2000.0    3.70350   3.306063   0.000    1.000   \n",
       "GLUCOSE                   2000.0  121.98000  30.563748  44.000   99.000   \n",
       "BLOODPRESSURE             2000.0   72.39300  11.961191  24.000   64.000   \n",
       "SKINTHICKNESS             2000.0   29.21300   9.217815   7.000   25.000   \n",
       "INSULIN                   2000.0  141.20100  84.007709  14.000  105.000   \n",
       "BMI                       2000.0   32.62445   7.194776  18.200   27.600   \n",
       "DIABETESPEDIGREEFUNCTION  2000.0    0.47093   0.323553   0.078    0.244   \n",
       "AGE                       2000.0   33.09050  11.786423  21.000   24.000   \n",
       "\n",
       "                              50%      75%     max  \n",
       "PREGNANCIES                 3.000    6.000   17.00  \n",
       "GLUCOSE                   117.000  141.000  199.00  \n",
       "BLOODPRESSURE              72.000   80.000  122.00  \n",
       "SKINTHICKNESS              28.000   32.000  110.00  \n",
       "INSULIN                   105.000  167.000  744.00  \n",
       "BMI                        32.300   36.800   80.60  \n",
       "DIABETESPEDIGREEFUNCTION    0.376    0.624    2.42  \n",
       "AGE                        29.000   40.000   81.00  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the outliers\n",
    "fig,axes=plt.subplots(figsize = (15,10))\n",
    "sns.boxplot(data=df, ax=axes,width=0.5) #draw the grapg of box plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabelEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = [col for col in df.columns if df[col].dtype not in [int, float] and df[col].nunique() == 2]\n",
    "len(binary_cols)#Using LabelEncoder, change the binary nominal feature to a binary integer 0 or 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in binary_cols:\n",
    "    label_encoder(df, col)\n",
    "\n",
    "df.head()\n",
    "#replace OUTCOME values to binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.hist(orientation='horizontal', figsize=(25,20)) #Plotting horizontal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " sns.pairplot(df, hue ='OUTCOME')# # Distribution of results on each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_map(df, plot=True)\n",
    "'''\n",
    "#If the correlation value is bigger than 0, there is a positive correlation. \n",
    " While the value of one variable increases, the value of the other variable also increases.  \n",
    " When there is equality of Correlation = 0 means no correlation. \n",
    " If the correlation is smaller than 0, there is a negative correlation. While one variable increases, the other variable decreases. \n",
    " When the correlations are examined, there are 2 variables that act as a positive correlation to the Outcome dependent variable. \n",
    " These variables are Glucose. As these increase, Outcome variable increases.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(df[\"OUTCOME\"])\n",
    "plt.title(\"Quantity of Diabetes\", size=10)\n",
    "plt.show()#View results histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation and training datasets without scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selection of data sets\n",
    "X = df.iloc[:,:-1].values#allocates the data\n",
    "y = df.iloc[:,-1].values#allocates the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset\n",
    "X_train,X_test,y_train,y_test =train_test_split(X,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Logistic Regression algorithm\n",
    "model_LR = LogisticRegression()\n",
    "model_LR.fit(X_train, y_train)#Fitting the values of x and y\n",
    "train_accuracy = model_LR.score(X_train, y_train)# Assign the training score \n",
    "test_accuracy = model_LR.score(X_test, y_test)#Assign testing score\n",
    "print(\"Logistic Regression model:\")\n",
    "print(\"Training model accuracy:{:.3f}\".format(train_accuracy))#Print Training Accuracy\n",
    "print(\"Testing model accuracy :{:.3f}\".format(test_accuracy))#Print Testing Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knn = KNeighborsClassifier()                #knn classifier\n",
    "model_knn.fit(X_train,y_train)#Fitting the values of x and y with the KNN model\n",
    "# Assign the training score \n",
    "train_accuracy = model_knn.score(X_train, y_train)\n",
    "test_accuracy = model_knn.score(X_test, y_test)#Assign testing score\n",
    "print(\" K-NN model:\")\n",
    "print(\"Training model_knn Accuracy:{:.3f}\".format(train_accuracy))#Print Training Accuracy\n",
    "print(\"Testing model_knn Accuracy: {:.3f}\".format(test_accuracy))#Print Testing Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Random Forest Classifier model\n",
    "model_RF = RandomForestClassifier(n_estimators=100,random_state=0)                \n",
    "model_RF.fit(X_train,y_train)#Fitting the values of x and y with the RandomForestClassifier model\n",
    "train_accuracy = model_RF.score(X_train, y_train)# Assign the training score \n",
    "test_accuracy = model_RF.score(X_test, y_test)#Assign testing score\n",
    "print(\" RandomForestClassifier model:\")\n",
    "print(\"Training model_RF Accuracy:{:.3f}\".format(train_accuracy))#Print Training Accuracy\n",
    "print(\"Testing model_RF Accuracy: {:.3f}\".format(test_accuracy))#Print Testing Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP = MLPClassifier(random_state=0)    # using MLPClassifier      \n",
    "MLP.fit(X_train,y_train) #Fitting the values of x and y with theMLPClassifier model\n",
    "MLP_train_accuracy = MLP.score(X_train, y_train)# Assign the training score \n",
    "MLP_test_accuracy = MLP.score(X_test, y_test)#Assign testing score\n",
    "print(\"MLPClassifierr model:\")\n",
    "print(\"Training model_tree without scalling Accuracy:{:.3f}\".format(MLP_train_accuracy)#Print Training Accuracy\n",
    "print(\"Testing model_tree without scalling Accuracy: {:.3f}\".format(MLP_test_accuracy))#Print Testing Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1].values#assign feature values\n",
    "pca = PCA(n_components = 2)#PCA class instance, the parameter value of the representative component is 2\n",
    "pComp = pca.fit_transform(X)#Fitted data\n",
    "PDF = pd.DataFrame(data = pComp, columns = ['pc1','pc2'])#generates a data frame from the 2 components\n",
    "PCA_df = pd.concat([PDF, df['OUTCOME']], axis = 1)#generates a data frame from the two components and target\n",
    "sns.relplot(data = PCA_df, x='pc1', y = 'pc2', hue = 'OUTCOME')#Plotting the distribution of \"OUTCOME\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics and Confusion matrix (without Scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix and Evaluation metrics\n",
    "y_test_LR = model_LR.predict(X_test)# make a prediction\n",
    "#creates the confusion matrix\n",
    "cfm_LR = confusion_matrix(y_test,y_test_LR)\n",
    "print(\"Logistic Regression model:\")\n",
    "print('confusion matrix:')\n",
    "print(cfm_LR)#print confusion matrix result\n",
    "print('Evaluation metrics:')#evaluation metrics for the model\n",
    "PDF = pd.DataFrame(data=#creates a dataframe \n",
    "[\n",
    "       [\n",
    "       accuracy_score(y_test,y_test_LR),#Accuracy classification score\n",
    "       recall_score(y_test,y_test_LR),# recall rate\n",
    "       precision_score(y_test,y_test_LR),#Precision rate\n",
    "       roc_auc_score(y_test,y_test_LR),#Predicted Receiver Operating Characteristic Curve  (ROC AUC) \n",
    "       f1_score(y_test, y_test_LR, average='micro')  #same like the accuracy_score\n",
    "       ]\n",
    "]\n",
    "       columns=['accuracy','recall','precision','roc_auc_score','f1_score'],index = ['Score'])#The name of each column and the Score associated with each value\n",
    "print(PDF)#prints the PDF with the evaluation metrics' scores\n",
    "Report =classification_report(y_test, y_test_LR)\n",
    "print('')\n",
    "print(Report)#print the classification_report\n",
    "plt.figure(figsize = (10,10))#sets the size of the figure\n",
    "sns.heatmap(data = cfm_LR, cmap=\"GnBu\",annot=True,fmt=\".0f\")#The heatmap contains the values within the PDF and is displayed inside the matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix and Evaluation metrics\n",
    "y_test_knn = model_knn.predict(X_test)# make a prediction\n",
    "#creates the confusion matrix\n",
    "cfm_knn = confusion_matrix(y_test,y_test_knn)\n",
    "print(\"K-NN model:\")\n",
    "print('confusion matrix:')\n",
    "print(cfm_knn)#print confusion matrix result\n",
    "print('Evaluation metrics:')#evaluation metrics for the model\n",
    "PDF = pd.DataFrame(data=#creates a dataframe \n",
    "[\n",
    "       [\n",
    "       accuracy_score(y_test,y_test_knn),#Accuracy classification score\n",
    "       recall_score(y_test,y_test_knn),# recall rate\n",
    "       precision_score(y_test,y_test_knn),#Precision rate\n",
    "       roc_auc_score(y_test,y_test_knn),#Predicted Receiver Operating Characteristic Curve  (ROC AUC) \n",
    "       f1_score(y_test, y_test_knn, average='micro')#same like the accuracy_score\n",
    "       ]\n",
    "],\n",
    "       columns=['accuracy','recall','precision','roc_auc_score','f1_score'],index = ['Score'])\n",
    "print(PDF)#prints the PDF with the evaluation metrics' scores\n",
    "Report =classification_report(y_test, y_test_knn)#creates the cReport of the model, which is a report showing the main classification metrics.\n",
    "print('')\n",
    "print(Report)#prints the classification_report\n",
    "plt.figure(figsize = (10,10))#sets the size of the figure\n",
    "sns.heatmap(data = cfm_knn, cmap=\"GnBu\",annot=True,fmt=\".0f\")#The heatmap contains the values within the PDF and is displayed inside the matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix and Evaluation metrics\n",
    "y_test_mlp = mlp.predict(X_test)# make a prediction\n",
    "#creates the confusion matrix\n",
    "cm_MLP = confusion_matrix(y_test,y_test_mlp)\n",
    "print(\"MLPClassifier model: \")\n",
    "print('confusion matrix:')\n",
    "print(cm_MLP)#print confusion matrix result\n",
    "print('Evaluation metrics:')#evaluation metrics for the model\n",
    "PDF = pd.DataFrame(data=#creates a dataframe \n",
    "[\n",
    "       [\n",
    "       accuracy_score(y_test,y_test_mlp),#Accuracy classification score\n",
    "       recall_score(y_test,y_test_mlp),# recall rate\n",
    "       precision_score(y_test,y_test_mlp),#Precision rate\n",
    "       roc_auc_score(y_test,y_test_mlp),#Predicted Receiver Operating Characteristic Curve  (ROC AUC) \n",
    "       f1_score(y_test, y_test_mlp, average='micro')#same like the accuracy_score\n",
    "       ]\n",
    "],\n",
    "       columns=['accuracy','recall','precision','roc_auc_score','f1_score'],index = ['Score'])\n",
    "print(PDF)#prints the PDF with the evaluation metrics' scores\n",
    "Report =classification_report(y_test, y_test_mlp)#creates the cReport of the model, which is a report showing the main classification metrics.\n",
    "print('')\n",
    "print(Report)#prints the classification_report\n",
    "plt.figure(figsize = (10,10))#sets the size of the figure\n",
    "sns.heatmap(data = cm_MLP, cmap=\"GnBu\",annot=True,fmt=\".0f\")#The heatmap contains the values within the PDF and is displayed inside the matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   Random Forest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix and Evaluation metrics\n",
    "y_test_RF = model_RF.predict(X_test)# make a prediction\n",
    "#creates the confusion matrix\n",
    "cm_RF = confusion_matrix(y_test,y_test_RF)\n",
    "print(\"RandomForestClassifier  model: \")\n",
    "print('confusion matrix:')\n",
    "print(cm_RF)#print confusion matrix result\n",
    "print('Evaluation metrics:')#evaluation metrics for the model\n",
    "PDF = pd.DataFrame(data=#creates a dataframe \n",
    "[\n",
    "       [\n",
    "       accuracy_score(y_test,y_test_RF),#Accuracy classification score\n",
    "       recall_score(y_test,y_test_RF),# recall rate\n",
    "       precision_score(y_test,y_test_RF),#Precision rate\n",
    "       roc_auc_score(y_test,y_test_RF),#Predicted Receiver Operating Characteristic Curve  (ROC AUC) \n",
    "       f1_score(y_test, y_test_RF, average='micro')#same like the accuracy_score\n",
    "       ]\n",
    "],\n",
    "       columns=['accuracy','recall','precision','roc_auc_score','f1_score'],index = ['Score'])\n",
    "print(PDF)#prints the PDF with the evaluation metrics' scores\n",
    "Report =classification_report(y_test, y_test_RF)#creates the cReport of the model, which is a report showing the main classification metrics.\n",
    "print('')\n",
    "print(Report)#prints the classification_report\n",
    "plt.figure(figsize = (10,10))#sets the size of the figure\n",
    "sns.heatmap(data = cm_RF, cmap=\"GnBu\",annot=True,fmt=\".0f\")#The heatmap contains the values within the PDF and is displayed inside the matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = plot_roc_curve(model_LR, X_test, y_test)\n",
    "plot_roc_curve(model_knn,X_test, y_test, ax = disp.ax_)\n",
    "plot_roc_curve(mlp,X_test, y_test, ax = disp.ax_)\n",
    "plot_roc_curve(model_RF, X_test, y_test,ax = disp.ax_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training datasets with scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1].values#data selectedand  give a  pandas series \n",
    "\n",
    "scaler = StandardScaler()#Pre-processed data\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])#Fit model with scaling features\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.25,random_state = 0)#Split dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Logistic Regression algorithm\n",
    "model_LRSC= LogisticRegression(max_iter=1000)#Use logistic regression and max_iter to 1000\n",
    "model_LRSC.fit(X_train, y_train)#Fit model with scaling features\n",
    "\n",
    "LRSC_train_accuracy = model_LRSC.score(X_train, y_train)# Assign the training score \n",
    "LRSC_test_accuracy = model_LRSC.score(X_test, y_test)#Assign testing score\n",
    "print(\"Logistic Regression model:\")\n",
    "print(\"Training model with scalling accuracy:{:.3f}\".format(LRSC_train_accuracy))#Print Training Accuracy\n",
    "print(\"Testing model with scalling accuracy :{:.3f}\".format(LRSC_test_accuracy))#Print Testing Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using K-NN algorithm\n",
    "model_knnSC = KNeighborsClassifier()       \n",
    "model_knnSC.fit(X_train,y_train)#Fitting the values of x and y with the KNN model\n",
    "# Assign the training score \n",
    "knnSC_train_accuracy = model_knnSC.score(X_train, y_train)\n",
    "knnSC_test_accuracy = model_knnSC.score(X_test, y_test)#Assign testing score\n",
    "print(\" K-NN model:\")\n",
    "print(\" Training model_knn with scalling Accuracy:{:.3f}\".format(knnSC_train_accuracy))#Print Training Accuracy\n",
    "print(\" Testing model_knn with scalling Accuracy: {:.3f}\".format(knnSC_test_accuracy))#Print Testing Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLPSC = MLPClassifier(random_state=0)    # using MLPClassifier      \n",
    "MLPSC.fit(X_train,y_train) #Fitting the values of x and y with theMLPClassifier model\n",
    "MLPSC_train_accuracy = MLPSC.score(X_train, y_train)# Assign the training score \n",
    "MLPSC_test_accuracy = MLPSC.score(X_test, y_test)#Assign testing score\n",
    "print(\"MLPClassifierr model:\")\n",
    "print(\"Training model_tree with scalling Accuracy:{:.3f}\".format(MLPSC_train_accuracy)#Print Training Accuracy\n",
    "print(\"Testing model_tree with scalling Accuracy: {:.3f}\".format(MLPSC_test_accuracy))#Print Testing Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Random Forest Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Random Forest Classifier model\n",
    "model_RFSC = RandomForestClassifier()                \n",
    "model_RFSC.fit(X_train,y_train)#Fitting the values of x and y with the RandomForestClassifier model\n",
    "\n",
    "RFSC_train_accuracy = model_RFSC.score(X_train, y_train)# Assign the training score \n",
    "RFSC_test_accuracy = model_RFSC.score(X_test, y_test)#Assign testing score\n",
    "print(\"Random Forest Classifier model:\")\n",
    "print(\"Training model_RF with scalling Accuracy:{:.3f}\".format(RFSC_train_accuracy))#Print Training Accuracy\n",
    "print(\"Testing model_RF with scalling Accuracy: {:.3f}\".format(RFSC_test_accuracy))#Print Testing Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,:-1].values#assign feature values\n",
    "pca = PCA(n_components = 2)#PCA class instance, the parameter value of the representative component is 2\n",
    "pComp = pca.fit_transform(X)#Fitted data\n",
    "PDF = pd.DataFrame(data = pComp, columns = ['pc1','pc2'])#generates a data frame from the 2 components\n",
    "PCA_df = pd.concat([PDF, df['OUTCOME']], axis = 1)#generates a data frame from the two components and target\n",
    "sns.relplot(data = PCA_df, x='pc1', y = 'pc2', hue = 'OUTCOME')#Plotting the distribution of \"OUTCOME\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics and Confusion matrix (Scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix and Evaluation metrics\n",
    "y_test_LRSC = model_LRSC.predict(X_test)# make a prediction\n",
    "#creates the confusion matrix\n",
    "cfm_LRSC = confusion_matrix(y_test,y_test_LRSC)\n",
    "print(\"Logistic Regression model:\")\n",
    "print('confusion matrix:')\n",
    "print(cfm_LRSC)#print confusion matrix result\n",
    "print('Evaluation metrics:')#evaluation metrics for the model\n",
    "PDF = pd.DataFrame(data=#creates a dataframe \n",
    "[\n",
    "       [\n",
    "       accuracy_score(y_test,y_test_LRSC),#Accuracy classification score\n",
    "       recall_score(y_test,y_test_LRSC),# recall rate\n",
    "       precision_score(y_test,y_test_LRSC),#Precision rate\n",
    "       roc_auc_score(y_test,y_test_LRSC),#Predicted Receiver Operating Characteristic Curve  (ROC AUC) \n",
    "       f1_score(y_test, y_test_LRSC, average='micro')  #same like the accuracy_score\n",
    "       ]\n",
    "]\n",
    "       columns=['accuracy','recall','precision','roc_auc_score','f1_score'],index = ['Score'])#The name of each column and the Score associated with each value\n",
    "print(PDF)#prints the PDF with the evaluation metrics' scores\n",
    "Report =classification_report(y_test, y_test_LRSC)\n",
    "print('')\n",
    "print(Report)#print the classification_report\n",
    "plt.figure(figsize = (10,10))#sets the size of the figure\n",
    "sns.heatmap(data = cfm_LRSC, cmap=\"GnBu\",annot=True,fmt=\".0f\")#The heatmap contains the values within the PDF and is displayed inside the matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix and Evaluation metrics\n",
    "y_test_knnSC = model_knnSC.predict(X_test)# make a prediction\n",
    "#creates the confusion matrix\n",
    "cfm_KNNSC = confusion_matrix(y_test,y_test_knnSC)\n",
    "print(\"K-NN model:\")\n",
    "print('confusion matrix:')\n",
    "print(cfm_KNNSC)#print confusion matrix result\n",
    "print('Evaluation metrics:')#evaluation metrics for the model\n",
    "PDF = pd.DataFrame(data=#creates a dataframe \n",
    "[\n",
    "       [\n",
    "       accuracy_score(y_test,y_test_knnSC),#Accuracy classification score\n",
    "       recall_score(y_test,y_test_knnSC),# recall rate\n",
    "       precision_score(y_test,y_test_knnSC),#Precision rate\n",
    "       roc_auc_score(y_test,y_test_knnSC),#Predicted Receiver Operating Characteristic Curve  (ROC AUC) \n",
    "       f1_score(y_test, y_test_knnSC, average='micro')#same like the accuracy_score\n",
    "       ]\n",
    "],\n",
    "       columns=['accuracy','recall','precision','roc_auc_score','f1_score'],index = ['Score'])\n",
    "print(PDF)#prints the PDF with the evaluation metrics' scores\n",
    "Report =classification_report(y_test, y_test_knnSC)#creates the cReport of the model, which is a report showing the main classification metrics.\n",
    "print('')\n",
    "print(Report)#prints the classification_report\n",
    "plt.figure(figsize = (10,10))#sets the size of the figure\n",
    "sns.heatmap(data = cfm_KNNSC, cmap=\"GnBu\",annot=True,fmt=\".0f\")#The heatmap contains the values within the PDF and is displayed inside the matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix and Evaluation metrics\n",
    "y_test_MLPSC = MLPSC.predict(X_test)# make a prediction\n",
    "#creates the confusion matrix\n",
    "cfm_MLPSC = confusion_matrix(y_test,y_test_MLPSC)\n",
    "print(\"MLPClassifier model: \")\n",
    "print('confusion matrix:')\n",
    "print(cfm_MLPSC)#print confusion matrix result\n",
    "print('Evaluation metrics:')#evaluation metrics for the model\n",
    "PDF = pd.DataFrame(data=#creates a dataframe \n",
    "[\n",
    "       [\n",
    "       accuracy_score(y_test,y_test_MLPSC),#Accuracy classification score\n",
    "       recall_score(y_test,y_test_MLPSC),# recall rate\n",
    "       precision_score(y_test,y_test_MLPSC),#Precision rate\n",
    "       roc_auc_score(y_test,y_test_MLPSC),#Predicted Receiver Operating Characteristic Curve  (ROC AUC) \n",
    "       f1_score(y_test, y_test_MLPSC, average='micro')#same like the accuracy_score\n",
    "       ]\n",
    "],\n",
    "       columns=['accuracy','recall','precision','roc_auc_score','f1_score'],index = ['Score'])\n",
    "print(PDF)#prints the PDF with the evaluation metrics' scores\n",
    "Report =classification_report(y_test, y_test_MLPSC)#creates the cReport of the model, which is a report showing the main classification metrics.\n",
    "print('')\n",
    "print(Report)#prints the classification_report\n",
    "plt.figure(figsize = (10,10))#sets the size of the figure\n",
    "sns.heatmap(data = cfm_MLPSC, cmap=\"GnBu\",annot=True,fmt=\".0f\")#The heatmap contains the values within the PDF and is displayed inside the matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix and Evaluation metrics\n",
    "y_test_RFSC = model_RFSC.predict(X_test)# make a prediction\n",
    "#creates the confusion matrix\n",
    "cfm_RFSC = confusion_matrix(y_test,y_test_RFSC)\n",
    "print(\"RandomForestClassifier  model: \")\n",
    "print('confusion matrix:')\n",
    "print(cfm_RFSC)#print confusion matrix result\n",
    "print('Evaluation metrics:')#evaluation metrics for the model\n",
    "PDF = pd.DataFrame(data=#creates a dataframe \n",
    "[\n",
    "       [\n",
    "       accuracy_score(y_test,y_test_RFSC),#Accuracy classification score\n",
    "       recall_score(y_test,y_test_RFSC),# recall rate\n",
    "       precision_score(y_test,y_test_RFSC),#Precision rate\n",
    "       roc_auc_score(y_test,y_test_RFSC),#Predicted Receiver Operating Characteristic Curve  (ROC AUC) \n",
    "       f1_score(y_test, y_test_RFSC, average='micro')#same like the accuracy_score\n",
    "       ]\n",
    "],\n",
    "       columns=['accuracy','recall','precision','roc_auc_score','f1_score'],index = ['Score'])\n",
    "print(PDF)#prints the PDF with the evaluation metrics' scores\n",
    "Report =classification_report(y_test, y_test_RFSC)#creates the cReport of the model, which is a report showing the main classification metrics.\n",
    "print('')\n",
    "print(Report)#prints the classification_report\n",
    "plt.figure(figsize = (10,10))#sets the size of the figure\n",
    "sns.heatmap(data = cfm_RFSC, cmap=\"GnBu\",annot=True,fmt=\".0f\")#The heatmap contains the values within the PDF and is displayed inside the matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning and Optimisation models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()                      #Solution help by Mark Elshaw \n",
    "LR_Dic=dict()# set dic and Getting indexes of values per hyper-parameter\n",
    "#Add Hyperparametrs\n",
    "LR_Dic['multi_class']= ['auto','ovr','multionmial']\n",
    "LR_Dic['solver']=['liblinear', 'saga','newton-cg', 'lbfgs', 'sag',]\n",
    "LR_Dic['penalty']= ['l1','l2','elasticnet','none']\n",
    "# LR_Dic['c_values']= [100, 10, 1.0, 0.1, 0.01, 0.001]  \n",
    "print(LR_Dic)#prints dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!  Dr. Trang Doan week6 solution\n",
    "\n",
    "grid_LR = GridSearchCV(model, LR_Dic, cv=5, scoring = \"accuracy\", return_train_score = False)# Perform a grid search\n",
    "grid_LR.fit(X,y)#Fit instances of Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_LR.best_score_)#print Best Score\n",
    "print(grid_LR.best_params_)#print Best parameter\n",
    "print(grid_LR.best_estimator_)#print estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid.cv_results_)[[\"mean_test_score\",\"params\"]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dr. Trang Doan weekk6 solution\n",
    "\n",
    "rand = RandomizedSearchCV(model, LR_Dic, cv =5, scoring =\"accuracy\", n_iter = 20, random_state =5, return_train_score = False)#performs random search on KNN\n",
    "rand.fit(X,y)#fits the X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rand.best_score_)#print Best Score\n",
    "print(rand.best_params_)#print Best para\n",
    "print(rand.best_estimator_)#print estimatormeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimised Logistic Regression  model and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_OP = LogisticRegression(C=100,multi_class='auto',penalty='l2',max_iter=1000,solver='liblinear',)\n",
    "model_OP.fit(X_train, y_train) \n",
    "train_accuracy_OP= model_OP.score(X_train, y_train)\n",
    "test_accuracy_OP = model_OP.score(X_test, y_test)\n",
    "#Cross-validation: evaluating estimator performance\n",
    "scores = cross_val_score(model_OP,X,y,cv = 5,scoring = 'accuracy')\n",
    "print(\"Logistic Regression model:\")\n",
    "print(\"Training model accuracy:{:.3f}\".format(train_accuracy_OP))\n",
    "print(\"Testing model accuracy :{:.3f}\".format(test_accuracy_OP))\n",
    "print(scores)\n",
    "print(\"Max score:{:.3f}\".format(scores.mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation metrics and Confusion matrix (Hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix and Evaluation metrics\n",
    "y_test_OP = model_OP.predict(X_test)\n",
    "#creates the confusion matrix\n",
    "cfm_LROP = confusion_matrix(y_test,y_test_OP)\n",
    "print(\"Logistic Regression model:\")\n",
    "print('confusion matrix:')\n",
    "print(cfm_LROP)#print confusion matrix result\n",
    "print('Evaluation metrics:')#evaluation metrics for the model\n",
    "PDF = pd.DataFrame(data=#creates a dataframe \n",
    "[\n",
    "       [\n",
    "       accuracy_score(y_test,y_test_OP),#Accuracy classification score\n",
    "       recall_score(y_test,y_test_OP),# recall rate\n",
    "       precision_score(y_test,y_test_OP),#Precision rate\n",
    "       roc_auc_score(y_test,y_test_OP),#Predicted Receiver Operating Characteristic Curve  (ROC AUC) \n",
    "       f1_score(y_test, y_test_OP, average='micro')  #same like the accuracy_score\n",
    "       ]\n",
    "]\n",
    "       columns=['accuracy','recall','precision','roc_auc_score','f1_score'],index = ['Score'])#The name of each column and the Score associated with each value\n",
    "print(PDF)#prints the PDF with the evaluation metrics' scores\n",
    "Report =classification_report(y_test, y_test_OP)\n",
    "print('')\n",
    "print(Report)#print the classification_report\n",
    "plt.figure(figsize = (10,10))#sets the size of the figure\n",
    "sns.heatmap(data = cfm_LROP, cmap=\"GnBu\",annot=True,fmt=\".0f\")#The heatmap contains the values within the PDF and is displayed inside the matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning for KNN\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train,y_train)#fit the model using X_train as training data and Y_train as target values\n",
    "k_range = list(range(1,31))# set n_neighbors range\n",
    "weights_options = ['uniform','distance']\n",
    "param_grid = dict(n_neighbors = k_range, weights = weights_options)\n",
    "print(param_grid)#prints dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!  Dr. Trang Doan week6 solution\n",
    "grid = GridSearchCV(model, param_grid, cv=5, scoring = \"accuracy\", return_train_score = False)#instance of Grid Search\n",
    "grid.fit(X,y)#fit the instance of gridsearch using X as training data and Y as target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)#print Best Score\n",
    "print(grid.best_params_)#print Best parameter\n",
    "print(grid.best_estimator_)#print estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid.cv_results_)[[\"mean_test_score\",\"params\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = RandomizedSearchCV(model, param_grid, cv =5, scoring = \"accuracy\", n_iter = 20, random_state =5, return_train_score = False)#performs random search on KNN\n",
    "rand.fit(X,y)#fits the X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rand.best_score_)#print Best Score\n",
    "print(rand.best_params_)#print Best para\n",
    "print(rand.best_estimator_)#print estimatormeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimised Logistic Regression  model and cross-validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using K-NN algorithm\n",
    "model_knnOP = KNeighborsClassifier(n_neighbors=15)                #knn classifier\n",
    "model_knnOP.fit(X_train,y_train)\n",
    "#Cross-validation: evaluating estimator performance\n",
    "scores = cross_val_score(model_knnOP,X,y,cv = 5,scoring = 'accuracy')\n",
    "knnOP_train_accuracy = model_knnOP.score(X_train, y_train)\n",
    "knnOP_test_accuracy = model_knnOP.score(X_test, y_test)\n",
    "print(\" K-NN model:\")\n",
    "print(scores)\n",
    "print(\" Training model_knn with scalling Accuracy:{:.3f}\".format(knnOP_train_accuracy))\n",
    "print(\" Testing model_knn withing Accuracy: {:.3f}\".format(knnOP_test_accuracy)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation metrics and Confusion matrix (Hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix and Evaluation metrics\n",
    "y_test_knnOP = model_knnOP.predict(X_test)\n",
    "#creates the confusion matrix\n",
    "cfm_KNNOP = confusion_matrix(y_test,y_test_knnOP)\n",
    "print(\"K-NN model:\")\n",
    "print('confusion matrix:')\n",
    "print(cfm_KNNOP)#print confusion matrix result\n",
    "print('Evaluation metrics:')#evaluation metrics for the model\n",
    "PDF = pd.DataFrame(data=#creates a dataframe \n",
    "[\n",
    "       [\n",
    "       accuracy_score(y_test,y_test_knnOP),#Accuracy classification score\n",
    "       recall_score(y_test,y_test_knnOP),# recall rate\n",
    "       precision_score(y_test,y_test_knnOP),#Precision rate\n",
    "       roc_auc_score(y_test,y_test_knnOP),#Predicted Receiver Operating Characteristic Curve  (ROC AUC) \n",
    "       f1_score(y_test, y_test_knnOP, average='micro')#same like the accuracy_score\n",
    "       ]\n",
    "],\n",
    "       columns=['accuracy','recall','precision','roc_auc_score','f1_score'],index = ['Score'])\n",
    "print(PDF)#prints the PDF with the evaluation metrics' scores\n",
    "Report =classification_report(y_test, y_test_knnOP)#creates the cReport of the model, which is a report showing the main classification metrics.\n",
    "print('')\n",
    "print(Report)#prints the classification_report\n",
    "plt.figure(figsize = (10,10))#sets the size of the figure\n",
    "sns.heatmap(data = cfm_KNNOP, cmap=\"GnBu\",annot=True,fmt=\".0f\")#The heatmap contains the values within the PDF and is displayed inside the matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)#hyperparameter tuning for RF\n",
    "model.fit(X_train,y_train)#fit the model using X_train as training data and Y_train as target values\n",
    "RF_DIC=dict()\n",
    "RF_DIC['class_weight']=['balanced', 'balanced_subsample']\n",
    "RF_DIC['criterion'] = ['gini','entropy']\n",
    "RF_DIC['max_features']=['auto', 'sqrt','log2']\n",
    "# RF_DIC['max_leaf_nodes'] = range(2,10)\n",
    "RF_DIC['min_samples_split'] = [2,3,4]\n",
    "RF_DIC['max_depth'] = range(1,10)\n",
    "print(RF_DIC)#prints dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!  Dr. Trang Doan week6 solution\n",
    "grid = GridSearchCV(model, RF_DIC, cv=5, scoring = \"accuracy\", return_train_score = False)#instance of Grid Search\n",
    "grid.fit(X,y)#fit the instance of gridsearch using X as training data and Y as target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)#print Best Score\n",
    "print(grid.best_params_)#print Best parameter\n",
    "print(grid.best_estimator_)#print estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!  Dr. Trang Doan week6 solution\n",
    "rand = RandomizedSearchCV(model, RF_DIC, cv =5, scoring = \"accuracy\", n_iter = 20, random_state =5, return_train_score = False)#performs random search on KNN\n",
    "rand.fit(X,y)#fits the X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rand.best_score_)#print Best Score\n",
    "print(rand.best_params_)#print Best para\n",
    "print(rand.best_estimator_)#print estimatormeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimised RandomForestClassifier model and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Random Forest Classifier model\n",
    "model_RFOP = RandomForestClassifier(n_estimators=100,random_state=0)                \n",
    "model_RFOP.fit(X_train,y_train)\n",
    "#Cross-validation: evaluating estimator performance\n",
    "scores = cross_val_score(model_RFOP,X,y,cv=5,scoring='accuracy')\n",
    "train_accuracy = model_RFOP.score(X_train, y_train)\n",
    "test_accuracy = model_RFOP.score(X_test, y_test)\n",
    "print(scores)\n",
    "print(\"Training model_RFOP Accuracy:{:.3f}\".format(train_accuracy))\n",
    "print(\"Testing model_RFOP Accuracy: {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation metrics and Confusion matrix (Hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix and Evaluation metrics\n",
    "y_test_RFOP = model_RFOP.predict(X_test)\n",
    "\n",
    "cfm_RFOP = confusion_matrix(y_test,y_test_RFOP)#creates the confusion matrix\n",
    "print(\"Logistic Regression model:\")\n",
    "print('confusion matrix:')\n",
    "print(cfm_RFOP)\n",
    "print('Evaluation metrics:')\n",
    "#evaluation metrics for the model\n",
    "#creates a dataframe which contains the value of the accuracy, recale, precision and roc_auc score\n",
    "PDF = pd.DataFrame(data=\n",
    "[\n",
    "       [\n",
    "       accuracy_score(y_test,y_test_RFOP),\n",
    "       recall_score(y_test,y_test_RFOP),\n",
    "       precision_score(y_test,y_test_RFOP),\n",
    "       roc_auc_score(y_test,y_test_RFOP),\n",
    "       f1_score(y_test, y_test_RFOP, average='micro')\n",
    "       ]\n",
    "],\n",
    "       columns=['accuracy','recall','precision','roc_auc_score','f1_score'],index = ['Score'])\n",
    "\n",
    "#creates a table with the accuracy, recall, precision and roc_auc scores\n",
    "labels = ['Probability of NOT having diabetes','Probability of having diabetes']#target names for classification report\n",
    "Report =classification_report(y_test, y_test_RFOP, target_names=labels)#creates the cReport of the model, which is a report showing the main classification metrics.\n",
    "print(Report)#prints the classification_report\n",
    "print(PDF)#prints the df with the score of the evaluation metrics\n",
    "\n",
    "plt.figure(figsize = (10,10))#sets the size of the figure\n",
    "sns.heatmap(data = cfm_RFOP, cmap=\"GnBu\",annot=True,fmt=\".0f\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier()    \n",
    "MLP_DIC=dict()# set dic and Getting indexes of values per hyper-parameter\n",
    "MLP_DIC['activation']=['identity', 'logistic', 'tanh', 'relu'] # set \n",
    "MLP_DIC['solver']=[ 'lbfgs', 'sgd','adam']\n",
    "MLP_DIC['learning_rate']=['constant','invscaling','adaptive']\n",
    "print(MLP_DIC) #prints dictionary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!  Dr. Trang Doan week6 solution\n",
    "grid = GridSearchCV(model, MLP_DIC, cv=5, scoring = \"accuracy\", return_train_score = False)#instance of Grid Search\n",
    "grid.fit(X,y)#fit the instance of gridsearch using X as training data and Y as target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_score_)#print Best Score\n",
    "print(grid.best_params_)#print Best parameter\n",
    "print(grid.best_estimator_)#print estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!  Dr. Trang Doan week6 solution\n",
    "rand = RandomizedSearchCV(model, MLP_DIC, cv =5, scoring = \"accuracy\", n_iter = 20, random_state =5, return_train_score = False)#performs random search on KNN\n",
    "rand.fit(X,y)#fits the X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rand.best_score_)#print Best Score\n",
    "print(rand.best_params_)#print Best para\n",
    "print(rand.best_estimator_)#print estimatormeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimised RandomForestClassifier model and cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train MLPClassifier\n",
    "MLP_OP = MLPClassifier(random_state=0,max_iter=1000,alpha=1)            \n",
    "MLP_OP .fit(X_train,y_train)\n",
    "#Cross-validation: evaluating estimator performance\n",
    "scores = cross_val_score(MLP_OP,X,y,cv = 5,scoring = 'accuracy')\n",
    "MLPOP_train_accuracy = MLP_OP.score(X_train, y_train)\n",
    "MLPOP_test_accuracy = MLP_OP .score(X_test, y_test)\n",
    "print(\"MLPClassifierr model:\")\n",
    "print(scores)\n",
    "print(\"Training MLP_OP  with scalling Accuracy:{:.3f}\".format(MLPOP_train_accuracy))\n",
    "print(\"Testing MLP_OP  with scalling Accuracy: {:.3f}\".format(MLPOP_test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation metrics and Confusion matrix (Hyperparameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix and Evaluation metrics\n",
    "y_test_MLPOP = MLP_OP.predict(X_test)\n",
    "#creates the confusion matrix\n",
    "cfm_MLPOP = confusion_matrix(y_test,y_test_MLPOP)\n",
    "print(\"MLPClassifier model:\")\n",
    "print('confusion matrix:')\n",
    "print(cfm_LROP)#print confusion matrix result\n",
    "print('Evaluation metrics:')#evaluation metrics for the model\n",
    "PDF = pd.DataFrame(data=#creates a dataframe \n",
    "[\n",
    "       [\n",
    "       accuracy_score(y_test,y_test_MLPOP),#Accuracy classification score\n",
    "       recall_score(y_test,y_test_MLPOP),# recall rate\n",
    "       precision_score(y_test,y_test_MLPOP),#Precision rate\n",
    "       roc_auc_score(y_test,y_test_MLPOP),#Predicted Receiver Operating Characteristic Curve  (ROC AUC) \n",
    "       f1_score(y_test, y_test_MLPOP, average='micro')  #same like the accuracy_score\n",
    "       ]\n",
    "]\n",
    "       columns=['accuracy','recall','precision','roc_auc_score','f1_score'],index = ['Score'])#The name of each column and the Score associated with each value\n",
    "print(PDF)#prints the PDF with the evaluation metrics' scores\n",
    "Report =classification_report(y_test, y_test_MLPOP)\n",
    "print('')\n",
    "print(Report)#print the classification_report\n",
    "plt.figure(figsize = (10,10))#sets the size of the figure\n",
    "sns.heatmap(data = cfm_MLPOP, cmap=\"GnBu\",annot=True,fmt=\".0f\")#The heatmap contains the values within the PDF and is displayed inside the matrix\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7cd546514abcdaaf9eaba3a8debdefe65d38cd3deeed0c62925429eba44c3a2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
